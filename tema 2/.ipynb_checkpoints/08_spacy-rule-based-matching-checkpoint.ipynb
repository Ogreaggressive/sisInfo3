{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "spacy.__version__\n",
    "nlp = spacy.load(\"es_core_news_md\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Emparejamiento basado en reglas"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Emparejar secuencias de tokens\n",
    "\n",
    "Un patrón de secuencia de tokens permite buscar patrones en el texto empleando los atributos lexicográficos y lingüísticos de los tokens; por ejemplo: nombre seguido de un adjetivo, nombre precedido por un artículo, etc. Los patrones de emparejamiento se definen como listas de diccionarios. Cada diccionario describe un atrobuto de un token. Las claves son los nombres de los atributos del token asociados a valores que se espera emparejar/buscar.\n",
    "\n",
    "<img src=\"09-spacy-secuencia-de-palabras-con-patrones_.png\" width=\"600px\"/>\n",
    "\n",
    "Por ejemplo, cuando se recibe una pregunta que comienza con una secuencia de palabras que usa el patrón \"verbo auxiliar + verbo\", como \"Podría enviar\", sabemos que la pregunta es sobre la capacidad, posibilidad, permiso u obligación de realizar la acción del verbo principal.\n",
    "\n",
    "**Referencias**\n",
    "\n",
    "- __[spaCy - Rule-based matching](https://spacy.io/usage/rule-based-matching)__\n",
    "- __[Available token attributes for Marcher](https://spacy.io/usage/rule-based-matching#adding-patterns-attributes)__ \n",
    "- __[Rule-based Matcher Explorer](https://explosion.ai/demos/matcher)__\n",
    "- __[An Overview of spaCy’s Token Matcher and Phrase Matcher](https://medium.com/featurepreneur/an-overview-of-spacys-token-matcher-and-phrase-matcher-8e68725c1fb1)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podría | POS: AUX, explain: auxiliary | lemma poder\n",
      "enviar | POS: VERB, explain: verb | lemma enviar\n",
      "un | POS: DET, explain: determiner | lemma uno\n",
      "pedido | POS: NOUN, explain: noun | lemma pedido\n",
      "mañana | POS: ADV, explain: adverb | lemma mañana\n",
      "? | POS: PUNCT, explain: punctuation | lemma ?\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Podría enviar un pedido mañana?')\n",
    "for token in doc:\n",
    "    print(f\"{token.text} | POS: {token.pos_}, explain: {spacy.explain(token.pos_)} | lemma {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.matcher import Matcher"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cómo usar el objeto Matcher\n",
    "# https://spacy.io/api/matcher\n",
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"POS\":\"AUX\", \"LEMMA\": \"poder\"},{\"POS\":\"VERB\"}]\n",
    "matcher.add(\"aux_verb_pattern\", [pattern])\n",
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Podría enviar\n"
     ]
    }
   ],
   "source": [
    "#matches es similar a [ (match_id, start, end), (match_id, start, end)... (match_id, start, end) ]\n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Cuantificadores y operadores\n",
    "\n",
    "Los cuantificadores permiten definir la frecuencia con la que el objeto __[Matcher](https://spacy.io/api/matcher)__ busca emperajmientos de un token.\n",
    "\n",
    "<img src=\"16-rule-based-matching-quantifiers.png\" width=\"600px\"/>\n",
    "\n",
    "- ```!```\tmatch 0 times.\n",
    "- ```?```\tmatch 0 or 1 times.\n",
    "- ```+```\tmatch 1 or more times.\n",
    "- ```*```\tmatch 0 or more times.\n",
    "\n",
    "Los operadores permiten realizar comparaciones diferentes a 'igual'\n",
    "\n",
    "<img src=\"17-rule-based-matching-comparison-operators.png\" width=\"800px\"/>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quería | POS: VERB, explain: verb | lemma querer\n",
      "enviar | POS: VERB, explain: verb | lemma enviar\n",
      "un | POS: DET, explain: determiner | lemma uno\n",
      "pedido | POS: ADJ, explain: adjective | lemma pedido\n",
      "mañana | POS: ADV, explain: adverb | lemma mañana\n",
      "? | POS: PUNCT, explain: punctuation | lemma ?\n"
     ]
    }
   ],
   "source": [
    "doc = nlp('Quería enviar un pedido mañana?')\n",
    "for token in doc:\n",
    "    print(f\"{token.text} | POS: {token.pos_}, explain: {spacy.explain(token.pos_)} | lemma {token.lemma_}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quería enviar\n"
     ]
    }
   ],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "pattern = [{\"LEMMA\": {\"IN\": [\"poder\", \"querer\"]}},{\"POS\":\"VERB\"}]\n",
    "matcher.add(\"aux_verb_pattern\", [pattern])\n",
    "matches = matcher(doc)\n",
    "            \n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## __[Expresiones regulares](https://spacy.io/usage/rule-based-matching#regex)__ y __[comodín](https://spacy.io/usage/rule-based-matching#adding-patterns-wildcard)__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Buen día\n",
      "Buenos días\n"
     ]
    }
   ],
   "source": [
    "#Expresiones regulares\n",
    "doc = nlp('Buen día. Buenos días')\n",
    "pattern = [{\"TEXT\": {\"REGEX\": \"[Bb]uen(os)?\"}}, {\"TEXT\": {\"REGEX\": \"[Dd]ía(s)?\"}}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"greeting\", [pattern])\n",
    "matches = matcher(doc)\n",
    "            \n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Enviamos el correo\n",
      "Enviar carta\n"
     ]
    }
   ],
   "source": [
    "# Comodín\n",
    "doc = nlp('Enviamos el correo. Enviar carta')\n",
    "# pattern = [{\"LEMMA\": \"enviar\"}, {}, {\"LOWER\": \"correo\"}]\n",
    "pattern = [{\"LEMMA\": \"enviar\"}, {'OP':'?'}, {\"POS\": \"NOUN\"}]\n",
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"send_mail\", [pattern])\n",
    "matches = matcher(doc)\n",
    "            \n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# [PhraseMatcher](https://spacy.io/api/phrasematcher)\n",
    "\n",
    "Facilia la búsqueda de frases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "texto = \"\"\"Ayer comenzó el Encuentro por la Salud y la Vida en Cochabamba con la presencia de más de mil \n",
    "personas entre profesionales de salud, dirigentes de la Central Obrera Bolivia\"\"\"\n",
    "doc = nlp( texto )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Central Obrera Bolivia\n"
     ]
    }
   ],
   "source": [
    "from spacy.matcher import PhraseMatcher\n",
    "\n",
    "matcher = PhraseMatcher(nlp.vocab)\n",
    "terms = [\"Central Obrera Bolivia\", \"COB\"]\n",
    "#El patrón de búsqueda es una lista de documentos\n",
    "patterns = [nlp.make_doc(text) for text in terms]\n",
    "matcher.add(\"cob_pattern\", patterns)\n",
    "matches = matcher(doc)\n",
    "            \n",
    "for match_id, start, end in matches:\n",
    "    print(doc[start:end])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
