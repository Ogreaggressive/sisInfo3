{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'3.3.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import spacy\n",
    "spacy.__version__"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# spaCy\n",
    "\n",
    "spaCy es una librería de código abierto para el procesamiento avanzado del lenguaje natural; incluye __[modelos ya entrenados en varios idiomas](https://spacy.io/usage/models)__, incluido el __[idioma español](https://spacy.io/models/es)__, que facilitan la extracción de características del texto que dependen del contexto.\n",
    "\n",
    "Puede __[instalar spaCy](https://spacy.io/usage)__ con este comando:\n",
    "\n",
    "<code>conda install -c conda-forge spacy</code>\n",
    "\n",
    "\n",
    "Una vez instalado spaCy puede descargar el modelo de lenguaje más apropiado a sus requerimientos de la siguiente manera\n",
    "\n",
    "<code>python -m spacy download es_core_news_md</code>\n",
    "\n",
    "\n",
    "Es recomendable ejecutar el comando anterior desde un consola con privilegios de administrador para evitar este tipo de errores: ```ERROR: Could not install packages due to an OSError: [WinError 5] Acceso denegado```:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# El flujo de procesamiento de texto (pipeline)\n",
    "\n",
    "\n",
    "Para facilitar el procesamient de texto, spaCy crea objetos contenedores que representan elementos como oraciones y palabras. Estos objetos, a su vez, tienen atributos que representan características lingüísticas, como la categoría gramatical (part-of-speech).\n",
    "\n",
    "El pipeline de procesamiento es un serie de funciones aplicadas el Doc para aumentar atributos como etiquetas __[POS](https://es.wikipedia.org/wiki/Etiquetado_gramatical)__, etiquetas de dependencia sintáctica o etiquetas __[NER](https://es.wikipedia.org/wiki/Reconocimiento_de_entidades_nombradas)__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'La ciudad de Sucre es la capital de Bolivia. La ciudad de La Paz está a 3600 metros sobre el nivel del mar. Microsoft fue multado por práctica monopólicas'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "texto = \"La ciudad de Sucre es la capital de Bolivia. La ciudad de La Paz está a 3600 metros sobre el nivel del mar. Microsoft fue multado por práctica monopólicas\"\n",
    "texto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[]\n",
      "[]\n"
     ]
    }
   ],
   "source": [
    "from spacy.lang.es import Spanish\n",
    "nlp = Spanish()\n",
    "print(nlp.pipe_names)\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La          0                        \n",
      "ciudad      0                        \n",
      "de          0                        \n",
      "Sucre       0                        \n",
      "es          0                        \n",
      "la          0                        \n",
      "capital     0                        \n",
      "de          0                        \n",
      "Bolivia     0                        \n",
      ".           1                        \n",
      "La          0                        \n",
      "ciudad      0                        \n",
      "de          0                        \n",
      "La          0                        \n",
      "Paz         0                        \n",
      "está        0                        \n",
      "a           0                        \n",
      "3600        0                        \n",
      "metros      0                        \n",
      "sobre       0                        \n",
      "el          0                        \n",
      "nivel       0                        \n",
      "del         0                        \n",
      "mar         0                        \n",
      ".           1                        \n",
      "Microsoft   0                        \n",
      "fue         0                        \n",
      "multado     0                        \n",
      "por         0                        \n",
      "práctica    0                        \n",
      "monopólicas 0                        \n"
     ]
    }
   ],
   "source": [
    "doc = nlp(texto)\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag and dependency label\n",
    "    token_text = token.text\n",
    "    is_punct = token.is_punct\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    # This is for formatting only\n",
    "    print('{:<12}{:<5}{:<10}{:<10}'.format(token_text, is_punct, token_pos, token_dep))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# si no haces el spacy.load no podras separar por sentencias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q.E.P.D nuestro querido amigo.\n",
      "Nuestro más sentido pésame a la familia.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Q.E.P.D nuestro querido amigo. Nuestro más sentido pésame a la familia.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Anotaciones agregadas por el pipeline de procesamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['tok2vec', 'morphologizer', 'parser', 'attribute_ruler', 'lemmatizer', 'ner']\n",
      "[('tok2vec', <spacy.pipeline.tok2vec.Tok2Vec object at 0x0000020D1C0A4FA0>), ('morphologizer', <spacy.pipeline.morphologizer.Morphologizer object at 0x0000020D1C0A4E20>), ('parser', <spacy.pipeline.dep_parser.DependencyParser object at 0x0000020D1BE40F90>), ('attribute_ruler', <spacy.pipeline.attributeruler.AttributeRuler object at 0x0000020D1C09CAC0>), ('lemmatizer', <spacy.lang.es.lemmatizer.SpanishLemmatizer object at 0x0000020D1BE7BE80>), ('ner', <spacy.pipeline.ner.EntityRecognizer object at 0x0000020D1C0F0120>)]\n"
     ]
    }
   ],
   "source": [
    "#Cargar el modelo del idioma español\n",
    "nlp = spacy.load(\"es_core_news_md\")\n",
    "print(nlp.pipe_names)\n",
    "print(nlp.pipeline)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Lemma, categoría gramatical y dependencias sintáctica"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "La            0    el          DET       det                 \n",
      "ciudad        0    ciudad      NOUN      nsubj               \n",
      "de            0    de          ADP       case                \n",
      "Sucre         0    Sucre       PROPN     nmod      LOC       \n",
      "es            0    ser         AUX       cop                 \n",
      "la            0    el          DET       det                 \n",
      "capital       0    capital     NOUN      ROOT                \n",
      "de            0    de          ADP       case                \n",
      "Bolivia       0    Bolivia     PROPN     nmod      LOC       \n",
      ".             1    .           PUNCT     punct     LOC       \n",
      "La            0    el          DET       det       LOC       \n",
      "ciudad        0    ciudad      NOUN      nsubj     LOC       \n",
      "de            0    de          ADP       case      LOC       \n",
      "La            0    el          DET       det       LOC       \n",
      "Paz           0    Paz         PROPN     nmod      LOC       \n",
      "está          0    estar       AUX       cop                 \n",
      "a             0    a           ADP       case                \n",
      "3600          0    3600        NUM       nummod              \n",
      "metros        0    metro       NOUN      ROOT                \n",
      "sobre         0    sobre       ADP       case                \n",
      "el            0    el          DET       det                 \n",
      "nivel         0    nivel       NOUN      nmod                \n",
      "del           0    del         ADP       case                \n",
      "mar           0    mar         NOUN      nmod                \n",
      ".             1    .           PUNCT     punct               \n",
      "Microsoft     0    Microsoft   PROPN     nsubj     ORG       \n",
      "fue           0    ser         AUX       aux                 \n",
      "multado       0    multar      VERB      ROOT                \n",
      "por           0    por         ADP       case                \n",
      "práctica      0    práctica    NOUN      obl                 \n",
      "monopólicas   0    monopólica  ADJ       obj                 \n"
     ]
    }
   ],
   "source": [
    "#Tokenize the text and apply each pipeline component in order.\n",
    "doc = nlp(texto)\n",
    "for token in doc:\n",
    "    # Get the token text, part-of-speech tag\n",
    "    token_text = token.text\n",
    "    is_punct = token.is_punct\n",
    "    token_lemma = token.lemma_\n",
    "    token_pos = token.pos_\n",
    "    token_dep = token.dep_\n",
    "    ent_type = token.ent_type_\n",
    "    print('{:<14}{:<5}{:<12}{:<10}{:<10}{:<10}'.format(token_text, is_punct, token_lemma, token_pos, token_dep, ent_type))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Companies, agencies, institutions, etc.'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.explain('ORG')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El componente 'parser' permite segmentar a nivel de oraciones."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Q.E.P.D nuestro querido amigo.\n",
      "Nuestro más sentido pésame a la familia.\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Q.E.P.D nuestro querido amigo. Nuestro más sentido pésame a la familia.\")\n",
    "for sent in doc.sents:\n",
    "    print(sent.text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### El componente 'parser' permite identificar sintagmas nominales."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[nuestro querido amigo, Nuestro más sentido, la familia]"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(doc.noun_chunks)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Lematización\n",
    "La __[lematización](https://es.wikipedia.org/wiki/Lematizaci%C3%B3n)__ es un proceso lingüístico que consiste en, dada una forma flexionada (es decir, en plural, en femenino, conjugada, etc), hallar el lema correspondiente. El lema es la forma que por convenio se acepta como representante de todas las formas flexionadas de una misma palabra. Es decir, el lema de una palabra es la palabra que nos encontraríamos como entrada en un diccionario tradicional: singular para sustantivos, masculino singular para adjetivos, infinitivo para verbos. Por ejemplo, decir es el lema de dije, pero también de diré o dijéramos; guapo es el lema de guapas; mesa es el lema de mesas.\n",
    "\n",
    "**La lematización facilita la búsqueda de palabras porque evita tener que tomar en cuenta las variaciones de ciertas palabras al momento de realizar búsquedas**. Por ejemplo, en lugar de que tener que buscar \"viajando\" o \"viajaba\" sólo tenemos que buscar \"viajar\". \n",
    "\n",
    "**Referencias**\n",
    "\n",
    "- __[Spacy - Lemmatization](https://spacy.io/usage/linguistic-features#lemmatization)__\n",
    "- __[NLP-03 Lemmatization and Stemming using spaCy](https://medium.com/mlearning-ai/nlp-03-lemmatization-and-stemming-using-spacy-b2829becceca)__\n",
    "\n",
    "*Otras referencias*\n",
    "- __[How to build a Lemmatizer](https://medium.com/analytics-vidhya/how-to-build-a-lemmatizer-7aeff7a1208c)__\n",
    "- __[How to solve Spanish lemmatization problems with SpaCy?](https://stackoverflow.com/questions/60534999/how-to-solve-spanish-lemmatization-problems-with-spacy)__\n",
    "- __[spacy-spanish-lemmatizer](https://github.com/pablodms/spacy-spanish-lemmatizer)__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estoy (lemma: estar)\n",
      "viajando (lemma: viajar)\n",
      "a (lemma: a)\n",
      "Cochabamba (lemma: Cochabamba)\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(u'Estoy viajando a Cochabamba')\n",
    "for token in doc:\n",
    "  print(f\"{token.text} (lemma: {token.lemma_})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Agregar un caso especial "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Estoy (lemma: estar)\n",
      "viajando (lemma: viajar)\n",
      "a (lemma: a)\n",
      "Cocha (lemma: Cochabamba)\n"
     ]
    }
   ],
   "source": [
    "\n",
    "nlp.get_pipe('attribute_ruler').add([[{\"TEXT\":\"Cocha\"}]],{\"LEMMA\":\"Cochabamba\"})\n",
    "\n",
    "doc = nlp(u'Estoy viajando a Cocha')\n",
    "\n",
    "for token in doc:\n",
    "  print(f\"{token.text} (lemma: {token.lemma_})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Ejercicio\n",
    "\n",
    "Encontrar en el siguiente texto todas las oraciones en las se habla de ```pasear``` y ```perro```\n",
    "\n",
    "```\n",
    "Esos gatos duermen mucho. Los gatos pasean cada Sábado por la mañana. A los perros les gusta pasear en el parque. Mi amigo gana unas monedas paseando los perros de sus vecinos.\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"Esos gatos duermen mucho. Los gatos pasean cada Sábado por la mañana. A los perros les gusta pasear en el parque. Mi amigo gana unas monedas paseando los perros de sus vecinos.\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Esos gatos duermen mucho. Los gatos pasean cada Sábado por la mañana. A los perros les gusta pasear en el parque. Mi amigo gana unas monedas paseando los perros de sus vecinos."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc = nlp(text)\n",
    "doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "#magister\n",
    "def verificarLemmas(sent):\n",
    "    lemas = [\"pasear\",\"perro\"]\n",
    "    doc = nlp(sent.text)\n",
    "    for token in doc:\n",
    "        if token.lemma_ in lemas:\n",
    "            return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[False, True, True, True]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#magister\n",
    "[verificarLemmas(sentence) for sentence in doc.sents]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Esos gatos duermen mucho.\n",
      "Los gatos pasean cada Sábado por la mañana.\n",
      "A los perros les gusta pasear en el parque.\n",
      "Mi amigo gana unas monedas paseando los perros de sus vecinos.\n"
     ]
    }
   ],
   "source": [
    "pasear = []\n",
    "perros =[]\n",
    "for sentence in doc.sents:\n",
    "    print(sentence)\n",
    "    for token in sentence:\n",
    "        if(token.lemma_ == \"pasear\"):\n",
    "            pasear.append(sentence)\n",
    "        if(token.lemma_ == \"perro\"):\n",
    "            perros.append(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Los gatos pasean cada Sábado por la mañana.,\n",
       " A los perros les gusta pasear en el parque.,\n",
       " Mi amigo gana unas monedas paseando los perros de sus vecinos.]"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pasear"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[A los perros les gusta pasear en el parque.,\n",
       " Mi amigo gana unas monedas paseando los perros de sus vecinos.]"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "perros"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Referencias\n",
    "\n",
    "\n",
    "- __[Natural Language Processing With spaCy in Python](https://realpython.com/natural-language-processing-spacy-python/)__\n",
    "- __[Token - Spacy](https://spacy.io/api/token)__\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
